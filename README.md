**This notebook demonstrates fundamental NLP preprocessing steps including:**

**• Tokenization**

**• Stopwords Removal**

**• Stemming**

**• Lemmatization**

**• Bag of Words (BOW) representation**

These are foundational techniques used in text preprocessing before applying machine learning or deep learning models.

---

![NLP_Notes](https://github.com/user-attachments/assets/587f1cbb-1476-4471-bd77-f51ebf560288)

---
**Summary**

**• Tokenization:** Splits text into words and sentences.

**• Stopwords Removal:** Removes common filler words.

**• Stemming:** Reduces words to crude root forms (may not always be valid words).

**• Lemmatization:** Converts words to meaningful dictionary root forms.

**• Bag of Words:** Converts text into numerical representation for ML models.
